{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "02a71244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Name: 7, Real Name: Subway, Count: 623\n",
      "Vectorized Name: 4, Real Name: Starbucks, Count: 537\n",
      "Vectorized Name: 1, Real Name: McDonald's, Count: 135\n",
      "Vectorized Name: 2, Real Name: McDonald's (Edgewood Road), Count: 2\n",
      "Vectorized Name: 5, Real Name: Starbucks Entrance, Count: 2\n",
      "Vectorized Name: 0, Real Name: Barnes & Noble/Starbucks, Count: 1\n",
      "Vectorized Name: 3, Real Name: McDonald's (Edgewood on Pulaski Highway/US 40), Count: 1\n",
      "Vectorized Name: 6, Real Name: Starbucks Reserve, Count: 1\n",
      "Vectorized Name: 8, Real Name: Town Center Blvd at McDonald's, Count: 1\n",
      "Vectorized Name: 9, Real Name: Wave Pool Subway, Count: 1\n",
      "Choose which identifiers you want to keep for your clusters and add to keepIdentifiers array\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def build_overpass_query(place_name, bbox=None):\n",
    "    overpass_query = \"\"\"\n",
    "    [out:json][timeout:25];\n",
    "    // gather results\n",
    "    (\n",
    "      node[\"name\"~\"{0}\"]{1};\n",
    "      way[\"name\"~\"{0}\"]{1};\n",
    "      relation[\"name\"~\"{0}\"]{1};\n",
    "    );\n",
    "    out body;\n",
    "    >;\n",
    "    out skel qt;\n",
    "    \"\"\".format(place_name, bbox if bbox else \";\")\n",
    "\n",
    "    return overpass_query\n",
    "\n",
    "def run_overpass_query(query):\n",
    "    overpass_url = \"https://overpass-api.de/api/interpreter\"\n",
    "    try:\n",
    "        response = requests.post(overpass_url, data={'data': query})\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "\n",
    "        result = response.json()\n",
    "\n",
    "        # Check if the response has elements\n",
    "        elements = result.get('elements', [])\n",
    "        places_data = []\n",
    "\n",
    "        if elements:\n",
    "            # Process the result\n",
    "            for node in elements:\n",
    "                # Check if the element has coordinates, an id, and a name\n",
    "                if 'lat' in node and 'lon' in node and 'id' in node and 'tags' in node and 'name' in node['tags']:\n",
    "                    place_id = node['id']\n",
    "                    name = node['tags']['name']\n",
    "                    latitude = node['lat']\n",
    "                    longitude = node['lon']\n",
    "                    places_data.append({'ID': place_id, 'Name': name, 'Latitude': latitude, 'Longitude': longitude})\n",
    "\n",
    "        return places_data\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request Error: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_combined_data(place_names, bbox=None):\n",
    "    combined_data = []\n",
    "\n",
    "    for place_name in place_names:\n",
    "        overpass_query = build_overpass_query(place_name, bbox)\n",
    "        place_data = run_overpass_query(overpass_query)\n",
    "\n",
    "        if place_data:\n",
    "            combined_data.extend(place_data)\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Example usage:\n",
    "place_names = [\"McDonald's\", \"Starbucks\", \"Subway\"]\n",
    "bbox = \"(37.4667, -79.3167, 40.3000, -74.7833)\"  # Replace with the desired bounding box\n",
    "\n",
    "combined_data = get_combined_data(place_names, bbox)\n",
    "\n",
    "# Create a DataFrame with ID, Name, X, Y, and Vectorized Name\n",
    "df = pd.DataFrame(combined_data)\n",
    "df['X'] = df['Longitude']\n",
    "df['Y'] = df['Latitude']\n",
    "\n",
    "# Use LabelEncoder to convert 'Name' to integer values\n",
    "label_encoder = LabelEncoder()\n",
    "df['Vectorized Name'] = label_encoder.fit_transform(df['Name'])\n",
    "\n",
    "# Save only 'X', 'Y', and 'Vectorized Name' columns to a text file without headers\n",
    "df[['X', 'Y', 'Vectorized Name']].to_csv('query_file.txt', index=False, header=False, sep='\\t')\n",
    "\n",
    "# Count occurrences of each vectorized name\n",
    "name_counts = df['Vectorized Name'].value_counts()\n",
    "\n",
    "# Display all names, vectorized names, and counts\n",
    "for vectorized_name, count in name_counts.items():\n",
    "    real_name = label_encoder.inverse_transform([vectorized_name])[0]\n",
    "    print(f\"Vectorized Name: {vectorized_name}, Real Name: {real_name}, Count: {count}\")\n",
    "\n",
    "print(\"Choose which identifiers you want to keep for your clusters and add to keepIdentifiers array\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de50084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
